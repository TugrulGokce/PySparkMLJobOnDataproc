{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0259e23e",
   "metadata": {},
   "source": [
    "|Variable     |Description |\n",
    "|:------------|:----------:|\n",
    "|id           |A notation for a house           |\n",
    "|date         |Date house was sold          |\n",
    "|price        |Price is prediction target           |\n",
    "|bedrooms     |Number of bedrooms           |\n",
    "|bathrooms    |Number of bathrooms           |\n",
    "|sqft_living  |Square footage of the home           |\n",
    "|sqft_lot     |Square footage of the lot           |\n",
    "|floors       |Total floors (levels) in house           |\n",
    "|waterfront   |House which has a view to a waterfront           |\n",
    "|view         |Has been viewed           |\n",
    "|condition    |How good the condition is overall           |\n",
    "|grade        |overall grade given to the housing unit, based on King County grading system           |\n",
    "|sqft_above   |Square footage of house apart from basement           |\n",
    "|sqft_basement|Square footage of the basement           |\n",
    "|yr_built     |Built Year           |\n",
    "|yr_renovated |Year when house was renovated           |\n",
    "|zipcode      |Zip code           |\n",
    "|lat          |Latitude coordinate           |\n",
    "|long         |Longitude coordinate           |\n",
    "|sqft_living15|Living room area in 2015(implies-- some renovations) This might or might not have affected the lotsize area|\n",
    "|sqft_lot15   |LotSize area in 2015(implies-- some renovations)           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf8f96",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d096bbd",
   "metadata": {},
   "source": [
    "## Creating Python File and Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef780673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spark_job.py\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--bucket\", help=\"bucket for input and output\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "BUCKET = args.bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca98f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, FloatType, DateType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Creating Spark Session\n",
    "spark = SparkSession.builder.appName(\"LinearRegression_with_HouseData\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "gcs_bucket='dataproc-staging-us-central1-1012630253058-dtwj7n8q/notebooks/jupyter/'\n",
    "data_file = \"gs://\" + gcs_bucket + \"kc_house_data.csv\"\n",
    "\n",
    "# reading csv\n",
    "house_df = spark.read.option(\"header\", True).csv(data_file) \n",
    "\n",
    "# changing date rows 20141013T000000 ---> 20141013\n",
    "house_df = house_df.withColumn(\"date\"\n",
    "                        ,when(house_df.date.endswith(\"T000000\"), regexp_replace(house_df.date,\"T000000\",\"\")))\n",
    "\n",
    "# changing data types required\n",
    "house_df = house_df.withColumn(\"id\", col(\"id\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"price\", col(\"price\").cast(FloatType())) \\\n",
    "                   .withColumn(\"bedrooms\", col(\"bedrooms\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"bathrooms\", col(\"bathrooms\").cast(FloatType())) \\\n",
    "                   .withColumn(\"sqft_living\", col(\"sqft_living\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"sqft_lot\", col(\"sqft_lot\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"floors\", col(\"floors\").cast(FloatType())) \\\n",
    "                   .withColumn(\"waterfront\", col(\"waterfront\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"view\", col(\"view\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"condition\", col(\"condition\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"grade\", col(\"grade\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"sqft_above\", col(\"sqft_above\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"sqft_basement\", col(\"sqft_basement\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"yr_built\", col(\"yr_built\").cast(DateType())) \\\n",
    "                   .withColumn(\"yr_renovated\", col(\"yr_renovated\").cast(DateType())) \\\n",
    "                   .withColumn(\"zipcode\", col(\"zipcode\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"lat\", col(\"lat\").cast(FloatType())) \\\n",
    "                   .withColumn(\"long\", col(\"long\").cast(FloatType())) \\\n",
    "                   .withColumn(\"sqft_living15\", col(\"sqft_living15\").cast(IntegerType())) \\\n",
    "                   .withColumn(\"sqft_lot15\", col(\"sqft_lot15\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba393e42",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b163b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "# Data exploration\n",
    "columns_for_lr = [\"floors\", \"waterfront\",\"lat\" ,\"bedrooms\" ,\"sqft_basement\" ,\"view\" ,\"bathrooms\",\"sqft_living15\",\"sqft_above\",\"grade\",\"sqft_living\", \"price\"]\n",
    "print(house_df.printSchema())\n",
    "print(house_df.select(columns_for_lr).show(5, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e3f914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "# Data Describe\n",
    "house_df[columns_for_lr].describe().toPandas().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec12da36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "# Correlation between features and target \n",
    "import six\n",
    "\n",
    "for i in house_df[columns_for_lr].columns:\n",
    "    if not( isinstance(house_df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print(\"Correlation to price for\", i, house_df.stat.corr('price',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582c0a2",
   "metadata": {},
   "source": [
    "### Preparing data from Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac25efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Preparing to Linear Regression\n",
    "features = [\"floors\", \"waterfront\",\"lat\" ,\"bedrooms\" ,\"sqft_basement\" ,\"view\" ,\"bathrooms\",\"sqft_living15\",\"sqft_above\",\"grade\",\"sqft_living\"] \n",
    "vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'Features')\n",
    "vhouse_df = vectorAssembler.transform(house_df)\n",
    "vhouse_df = vhouse_df.select(['Features', 'price'])\n",
    "print(\"\\nAfter Vector Assembling\")\n",
    "vhouse_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e57fd",
   "metadata": {},
   "source": [
    "## Traint Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ea9742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "# Training, Test Split\n",
    "(trainingData, testData) = vhouse_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "print(\"Training data\")\n",
    "print(trainingData.show(5))\n",
    "\n",
    "print(\"\\nTest data\")\n",
    "print(testData.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd5813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "print(\"Total trainingData instance :\", trainingData.count(),\"\\nTotal testData instance :\", testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576da63c",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbaa8897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "print(\"*** Linear Regression ***\")\n",
    "lr = LinearRegression(featuresCol = 'Features', labelCol='price', maxIter = 20, regParam = 0.3, elasticNetParam = 0.8)\n",
    "lr_model = lr.fit(trainingData)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7aab8c",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e6e268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"Model Summary for Linear Regression\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e2bce",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a83d1064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "print(\"Prediction for Linear Regression Model\")\n",
    "print(\"--------------------------------------\")\n",
    "lr_predictions = lr_model.transform(testData)\n",
    "lr_predictions.select(\"features\",\"price\",\"prediction\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluator for test data\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"price\",\n",
    "                                   predictionCol=\"prediction\",\n",
    "                                   metricName=\"r2\")\n",
    "\n",
    "# R2 score for test data\n",
    "r2 = lr_evaluator.evaluate(lr_predictions)\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbefe599",
   "metadata": {},
   "source": [
    "# Gradient-boosted Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d644db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Gradient-boosted Tree Regression\n",
    "gbt = GBTRegressor(featuresCol = 'Features', labelCol = 'price', maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_predictions = gbt_model.transform(testData)\n",
    "print(\"\\n*** Gradient-boosted Tree Regression *** \")\n",
    "gbt_predictions.select('prediction', 'price', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeac480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "# Gradient-boosted Tree Regression Evaluator\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"\\n*** Gradient-boosted Tree Regression - R Squared (R2) Score *** \")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"R Squared (R2) on test data = %g\" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df531e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef688ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to spark_job.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a spark_job.py\n",
    "\n",
    "import google.cloud.storage as gcs\n",
    "bucket = gcs.Client().get_bucket(BUCKET)\n",
    "for blob in bucket.list_blobs(prefix='sparkml/'):\n",
    "    blob.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b275798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to projects-de\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/07 16:17:26 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/02/07 16:17:26 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/02/07 16:17:26 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/02/07 16:17:26 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "root                                                                            \n",
      " |-- id: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: float (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: float (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- sqft_above: integer (nullable = true)\n",
      " |-- sqft_basement: integer (nullable = true)\n",
      " |-- yr_built: date (nullable = true)\n",
      " |-- yr_renovated: date (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: float (nullable = true)\n",
      " |-- long: float (nullable = true)\n",
      " |-- sqft_living15: integer (nullable = true)\n",
      " |-- sqft_lot15: integer (nullable = true)\n",
      "\n",
      "None\n",
      "+------+----------+-------+--------+-------------+----+---------+-------------+----------+-----+-----------+--------+\n",
      "|floors|waterfront|    lat|bedrooms|sqft_basement|view|bathrooms|sqft_living15|sqft_above|grade|sqft_living|   price|\n",
      "+------+----------+-------+--------+-------------+----+---------+-------------+----------+-----+-----------+--------+\n",
      "|   1.0|         0|47.5112|       3|            0|   0|      1.0|         1340|      1180|    7|       1180|221900.0|\n",
      "|   2.0|         0| 47.721|       3|          400|   0|     2.25|         1690|      2170|    7|       2570|538000.0|\n",
      "|   1.0|         0|47.7379|       2|            0|   0|      1.0|         2720|       770|    6|        770|180000.0|\n",
      "|   1.0|         0|47.5208|       4|          910|   0|      3.0|         1360|      1050|    7|       1960|604000.0|\n",
      "|   1.0|         0|47.6168|       3|            0|   0|      2.0|         1800|      1680|    8|       1680|510000.0|\n",
      "+------+----------+-------+--------+-------------+----+---------+-------------+----------+-----+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "Correlation to price for floors 0.25679388755071897                             \n",
      "Correlation to price for waterfront 0.26636943403060204\n",
      "Correlation to price for lat 0.307003482637723\n",
      "Correlation to price for bedrooms 0.30834959814563934\n",
      "Correlation to price for sqft_basement 0.32381602071198434\n",
      "Correlation to price for view 0.39729348829450273\n",
      "Correlation to price for bathrooms 0.5251375054139628\n",
      "Correlation to price for sqft_living15 0.5853789035795692\n",
      "Correlation to price for sqft_above 0.6055672983560784\n",
      "Correlation to price for grade 0.6674342560202353\n",
      "Correlation to price for sqft_living 0.7020350546118005\n",
      "Correlation to price for price 1.0\n",
      "\n",
      "After Vector Assembling\n",
      "+--------------------+--------+                                                 \n",
      "|            Features|   price|\n",
      "+--------------------+--------+\n",
      "|[1.0,0.0,47.51119...|221900.0|\n",
      "|[2.0,0.0,47.72100...|538000.0|\n",
      "|[1.0,0.0,47.73789...|180000.0|\n",
      "|[1.0,0.0,47.52080...|604000.0|\n",
      "|[1.0,0.0,47.61679...|510000.0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Training data\n",
      "+--------------------+--------+                                                 \n",
      "|            Features|   price|\n",
      "+--------------------+--------+\n",
      "|(11,[0,2,7,8,9,10...|139950.0|\n",
      "|[1.0,0.0,47.16469...|335000.0|\n",
      "|[1.0,0.0,47.17639...|245000.0|\n",
      "|[1.0,0.0,47.17750...|360000.0|\n",
      "|[1.0,0.0,47.18030...|265000.0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "\n",
      "Test data\n",
      "+--------------------+---------+                                                \n",
      "|            Features|    price|\n",
      "+--------------------+---------+\n",
      "|(11,[0,2,7,8,9,10...| 142000.0|\n",
      "|(11,[0,2,7,8,9,10...| 355000.0|\n",
      "|(11,[0,2,7,8,9,10...| 235000.0|\n",
      "|(11,[0,2,7,8,9,10...|1295650.0|\n",
      "|[1.0,0.0,47.19480...| 202000.0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "Total trainingData instance : 15235                                             \n",
      "Total testData instance : 6378\n",
      "*** Linear Regression ***\n",
      "Coefficients: [-30660.535868398616,578746.7437850905,670808.7184523258,-26263.309615786056,93.87723899322152,67593.42688434735,-4507.760843579713,-1.64289420232773,94.82642826479275,83968.31345873275,101.41968484549425]\n",
      "\n",
      "Intercept: -32288411.700666144\n",
      "Model Summary for Linear Regression\n",
      "-----------------------------------\n",
      "RMSE: 213207.324139\n",
      "r2: 0.660045\n",
      "Prediction for Linear Regression Model\n",
      "--------------------------------------\n",
      "+--------------------+---------+-------------------+                            \n",
      "|            features|    price|         prediction|\n",
      "+--------------------+---------+-------------------+\n",
      "|(11,[0,2,7,8,9,10...| 142000.0|-296779.09394220635|\n",
      "|(11,[0,2,7,8,9,10...| 355000.0|  603345.0994797312|\n",
      "|(11,[0,2,7,8,9,10...| 235000.0|  405976.7685938291|\n",
      "|(11,[0,2,7,8,9,10...|1295650.0| 1567604.2780584842|\n",
      "|[1.0,0.0,47.19480...| 202000.0|  34748.99821056798|\n",
      "+--------------------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.651851                                          \n",
      "                                                                                \n",
      "*** Gradient-boosted Tree Regression *** \n",
      "+------------------+---------+--------------------+                             \n",
      "|        prediction|    price|            features|\n",
      "+------------------+---------+--------------------+\n",
      "| 213897.7929077913| 142000.0|(11,[0,2,7,8,9,10...|\n",
      "|357369.12227864476| 355000.0|(11,[0,2,7,8,9,10...|\n",
      "|240463.42142687933| 235000.0|(11,[0,2,7,8,9,10...|\n",
      "|1770921.4888715036|1295650.0|(11,[0,2,7,8,9,10...|\n",
      "| 221810.4575911119| 202000.0|[1.0,0.0,47.19480...|\n",
      "+------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "                                                                                \n",
      "*** Gradient-boosted Tree Regression - R Squared (R2) Score *** \n",
      "---------------------------------------------------------------\n",
      "R Squared (R2) on test data = 0.735267\n"
     ]
    }
   ],
   "source": [
    "BUCKET= 'projects-de' \n",
    "print('Writing to {}'.format(BUCKET))\n",
    "!python spark_job.py --bucket=$BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf5705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb0050b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://spark_job.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  5.9 KiB/  5.9 KiB]                                                \n",
      "Operation completed over 1 objects/5.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp spark_job.py gs://projects-de/sparkml/spark_job.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c55b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://projects-de/sparkml/spark_job.py\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://$BUCKET/**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}